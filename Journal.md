# Journal de bord du projet encadr√©

### S√©ance 1
Le premier cours se concentre principalement sur l'apprentissage de la compr√©hension des ordinateurs et des concepts de base et de l'utilisation des commandes du syst√®me Unix.
#### 1. Un ordinateur est compos√© de plusieurs couches¬†:
- Hardware ‚Üí Kernel ‚Üí Shell ‚Üí Utilities
- Nous interagissons avec le syst√®me d'exploitation via un shell
#### 2. Unix
- ‚ö†Ô∏è Tout est fichier (C'est tr√®s abstrait, et je pense qu'il faudra beaucoup de temps pour vraiment comprendre le concept.)
- La structure hi√©rarchique des fichiers et des r√©pertoires (dossiers) : Tout comme s'√©tendant de la racine d'un arbre jusqu'aux feuilles, cette branche est appel√©e le chemin pour trouver le fichier (feuille).
- Traitement des fichiers avec des commandes : nom [-option...] [arguments...]
#### 3. Difficult√© :
- Nous devons toujours savoir dans quel fichier nous nous trouvons pour passer √† l'√©tape suivante(trouvez le bon chemin)
- La compr√©hension et l'utilisation des commandes(Nous devons nous familiariser avec de nombreuses commandes et leurs param√®tres (options), et devons ensuite souvent connecter plusieurs commandes via le symbole pipe |, ce qui n√©cessite une certaine r√©flexion logique.)

---

### S√©ance 2
Git et GitHub
#### 1. Diff√©rence
- Git est un syst√®me de gestion de versions (SGV). Il nous permet d'enregistrer chaque modification apport√©e √† un fichier, de conserver son historique et de revenir aux versions pr√©c√©dentes.
- GitHub est une plateforme en ligne bas√©e sur Git qui nous permet de t√©l√©charger notre code local sur le cloud pour collaborer, partager et discuter avec d'autres personnes.
- Je comprends que Git est un outil et que GitHub est une plateforme.
#### 2. D√©poser mes travail sur Git
J'ai test√© quelques-unes des commandes Git les plus courantes¬†: git add, git commit -m "message", etc. J'ai constat√© que, m√™me si ces commandes peuvent para√Ætre un peu complexes √† m√©moriser au premier abord, leur d√©roulement est en r√©alit√© tr√®s logique¬†:
```bash
¬´¬†pull ‚Üí add ‚Üí commit ‚Üí push ‚Üí tag¬†¬ª 
```
est un processus standard.
#### 3. Manipulation des fichiers
Comme je l‚Äôai mentionn√© dans la S√©ance 1, les commandes pour manipuler les fichiers sont parfois complexes et difficiles √† m√©moriser.
Afin de mieux comprendre leur utilisation, j‚Äôai cr√©√© un tableau r√©capitulatif qui contient :
```bash
les options de chaque commande
leurs arguments
et une explication en chinois pour m‚Äôaider √† les retenir plus facilement
```
Cette m√©thode m‚Äôaide non seulement √† m√©moriser plus efficacement, mais aussi √† comparer les commandes entre elles.
Je me rends compte qu‚Äôil existe encore beaucoup de commandes que je ne connais pas, donc le plus important pour moi est de continuer √† explorer et √† pratiquer.

---

### S√©ance 3
Pipelines
#### 1. Les commandes se communiquent
Dans cette partie du cours, j‚Äôai appris √† manipuler les flux d‚Äôentr√©es et de sorties (stdin, stdout, stderr) dans Unix. Avant, je ne savais pas vraiment comment les commandes ‚Äúcommuniquent‚Äù entre elles, mais maintenant je comprends que tout passe par des flux de donn√©es.

les commandes peuvent rediriger leurs entr√©es et sorties vers des fichiers :
```bash
> envoie la sortie dans un fichier
>> ajoute la sortie √† la fin d‚Äôun fichier
< lit l‚Äôentr√©e √† partir d‚Äôun fichier
Exemple : wc < texte.txt > compte.txt ‚û°Ô∏è lit un fichier et enregistre le r√©sultat dans un autre, sans rien afficher √† l‚Äô√©cran.
```
#### 2. Les pipelines |
Le pipe |, qui permet d‚Äôenvoyer la sortie d‚Äôune commande comme entr√©e d‚Äôune autre. elle permet aussi de combiner des commandes simples pour r√©aliser des traitements complexes.
Exemple :
```bash
cat *.txt | grep "universit√©" | wc -l
‚û°Ô∏è Cette commande compte le nombre de lignes contenant le mot "universit√©" dans tous les fichiers texte du r√©pertoire courant.
```
J'ai √©galement appris beaucoup de commandes utiles ici : grep, sort, etc. Je les ai ajout√©es √† ma liste de commandes comme d'habitude pour une visualisation et une m√©morisation faciles.

---

### S√©ance 4
Nous avons appris deux boucles : 
```bash
1. for ‚û°Ô∏è parcourir les √©l√©ments
2. while ‚û°Ô∏è faire quelques choses tant que la condition est vrai
üëÜ comme les boucles dans python
```
Explication du code :
```bash
#!/usr/bin/bash # on est dans le shell bash
if [ $# -ne 1 ] # v√©rifier si on re√ßoit 1 argument
then #si la condition est vrai, c-√†-d on n'a pas re√ßu 1 argument
  echo "ce programme demande un argument" #print cette messages pour demander un entr√©e d'un argument
    exit # sort de ce boucle
fi # pour dire √† ordinateur c'est la fin de la boucle
FICHIER_URLS=$1 #un argument nomm√© FICHIER_URLS
OK =0 #initialiser compteur OK
NOK =0 #initialiser compteur OK
while read -r LINE; #lire ce fichier par ligne
do
  echo "la ligne: $LINE" #print ce qu'on a lit de cette ligne
  if [[ $LINE =‚àº ^https?:// ]] #v√©rifier si cette ligne est commenc√© par http:// ou https://
  then #si oui 
    echo "ressemble √† une URL valide" #print la message pour dire que le contenu de cette ligne ressemble √† une URL valide
    OK=$(expr $OK + 1) #compteur des URL valide plus 1
  else #sinon
    echo "ne ressemble pas √† une URL valide" ##print la message pour dire que le contenu de cette ligne ne ressemble pas √† une URL valide
    NOK=$(expr $NOK + 1) #compteur des URL non valide plus 1
  fi #la fin du boucle
done < $FICHIER_URLS #le contenu du fichier est redirig√© vers la boucle while
echo "$OK URLs et $NOK lignes douteuses" #print notre r√©sultat du nombre des URL valide et non valide
```

---

### S√©ance 5

R√©flexions et probl√®mes rencontr√©s en faisant les devoirs

Code √† √©laborer :
```bash
while read -r line;
do
    nb=nb+1
	echo ${line};
done < "$ficher_URLS";
```

Question 1 : Pourquoi ne pas utiliser cat ?  
Concernant la premi√®re question concernant le miniprojet, je ne suis pas tout √† fait s√ªr de sa signification. Je vais donc simplement expliquer mon point de vue sur cat et while¬†: l'un ne fait que lire, tandis que l'autre g√®re le traitement. Cela signifie-t-il qu'on peut utiliser cat et read simultan√©ment¬†? Je ne pense pas que ce soit n√©cessaire, car read g√®re d√©j√† la lecture de fichiers dans while. J'esp√®re que mon professeur pourra r√©pondre √† ma question lors de la r√©vision de nos devoirs apr√®s les vacances.

Question 2 : Comment transformer "urls/fr.txt" en param√®tre du script ?  
Ce probl√®me est relativement simple √† r√©soudre. Nous d√©finissons le chemin d'acc√®s au fichier comme param√®tre, de sorte que lors de l'ex√©cution de notre fichier sh, nous devons utiliser le chemin d'acc√®s du fichier d'entr√©e pour ex√©cuter notre boucle.
```bash
ficher_URLS=$1 #Cela signifie qu'il faut attribuer le premier param√®tre inject√© √† la variable ficher_URLS
while read -r line;
do
    nb=nb+1
	echo "$nb   ${line}";
done < "$ficher_URLS"; #En cons√©quence, le contenu du fichier saisi ici utilise √©galement nos variables
```
2.1 Valider l‚Äôargument : ajouter le code n√©cessaire pour s‚Äôassurer qu‚Äôon donne bien un argument au script, sinon on s‚Äôarr√™te  
Ici, j'ai ajout√© deux conditions¬†: l'une pour v√©rifier le nombre de param√®tres d'entr√©e, et l'autre pour v√©rifier si le param√®tre d'entr√©e est un Fisher. Dans le cas contraire, des informations seront fournies √† l'utilisateur.
```bash
ficher_URLS=$1

if [ $# -ne 1 ]
then
    echo "ce programme demande un argument"
    exit
fi

if [ ! -f "$ficher_URLS" ]
then
    echo "vous devez indiquer un ficher"
    exit
fi

while read -r line;
do
	echo "$nb   ${line}";
done < "$ficher_URLS";
```
‚ö†Ô∏èIl convient de noter que si notre affectation de param√®tres est effectu√©e apr√®s la condition de v√©rification du chemin, le nom du param√®tre dans notre condition if ne peut pas utiliser $ficher_URLS, car nous n'avons pas d√©fini le param√®tre √† ce moment.  

3. Comment afficher le num√©ro de ligne avant chaque URL (sur la m√™me ligne) ?
   - Bien s√©parer les valeurs par des tabulations
Pour r√©soudre ce probl√®me, nous pouvons ajouter un compteur nb pour faciliter le comptage, en comptant de la premi√®re √† la derni√®re URL, et en pla√ßant le nombre nb compt√© √† chaque fois devant l'URL affich√©e. Je l'ai initialement √©crit ainsi¬†:
```bash
nb=0
while read -r line;
do
    nb=nb+1
	echo "$nb   ${line}";
done < "$ficher_URLS";
```
Mais j'ai constat√© que chaque URL ex√©cut√©e √©tait pr√©c√©d√©e de ¬´¬†nb+1¬†¬ª au lieu du num√©ro attendu. Il devait donc y avoir une erreur dans mon affectation de nb. J'ai ensuite relu le didacticiel de la le√ßon pr√©c√©dente et constat√© que pour effectuer une op√©ration math√©matique sur une variable d√©finie pr√©c√©demment, je devais l'√©crire ainsi¬†:
```bash
OK =0
OK=$(expr $OK + 1)
```
Voici le code modifi√©¬†:
```bash
nb=0
while read -r line;
do
    nb=$(expr $nb + 1)
	echo "$nb   ${line}";
done < "$ficher_URLS";
```
Le r√©sultat de cette ex√©cution correspond √† ce que nous recherchons.

La partie suivante √©tait beaucoup plus complexe. J'ai utilis√© ChatGPT pour l'interroger sur les erreurs de mon code et sur certaines options curl. Pour la deuxi√®me partie, nous devions d'abord afficher le code HTTP de chaque lien, comme pour les 1XX, 200, etc. vus en cours. Comme j'avais d√©j√† abord√© ce sujet en cours, j'ai trouv√© cela relativement simple. J'ai d'abord utilis√© curl -I pour extraire les m√©tadonn√©es du lien. J'ai observ√© le code dont nous avions besoin dans cette section¬†:
```bash
HTTP/2 200
```
Autrement dit, il me suffit d'utiliser grep pour trouver le mot HTTP et extraire le num√©ro de code de la deuxi√®me colonne. J'utilise le code suivant pour impl√©menter mon id√©e¬†:
```bash
code_http=$(curl -I -s $line | grep HTTP | cut -d ' ' -f2)
# J'ai d√©fini la variable code_http pour stocker chaque code http. L'option ¬´¬†-s¬†¬ª permet de mieux visualiser les m√©tadonn√©es, et ¬´¬†cut¬†¬ª permet d'extraire uniquement la partie souhait√©e. J'utilise ¬´¬†-d¬†¬ª pour s√©parer la ligne HTTP par un espace et ¬´¬†-f2¬†¬ª pour extraire uniquement la deuxi√®me colonne.
```
Les deux √©tapes suivantes pour extraire l'encodage et le nombre de mots d'une page web sont similaires √† la m√©thode pr√©c√©dente. J'ajoute √©galement deux op√©rations d'√©cho pour convertir mon r√©sultat en tableau. Voici l'int√©gralit√© de mon code¬†:
```bash
ficher_URLS=$1
#    2.1 Valider l‚Äôargument : ajouter le code n√©cessaire pour s‚Äôassurer qu‚Äôon donne bien un argument au script, sinon on s‚Äôarr√™te

# v√©rifier si on a bien argument
if [ $# -ne 1 ]
then
    echo "ce programme demande un argument"
    exit
fi

# v√©rifier l'argument est bien un ficher
if [ ! -f "$ficher_URLS" ]
then
    echo "vous devez indiquer un ficher"
    exit
fi

echo -e "nb\tline\tcode_http\tencodage\tnb_mot" > tableaux/tableau.tsv

nb=0
meta=""
code_http=""
encodage=""
nb_mot=""
while read -r line;
do
    nb=$(expr $nb + 1)
    metadonnee=$(curl -I -s -L "$line")
    code_http=$( echo "${metadonnee}" | grep HTTP | cut -d ' ' -f2)
    encodage=$( echo "${metadonnee}" | grep charset | cut -d '=' -f2 | tr -d '\r')
    nb_mot=$( curl -s -L "$line" | wc -w )

    if [ "$code_http" != "200" ]
    then
        code_http="Page_Not_Found"
    fi

    if [ ! "$encodage" ]
    then
        encodage="No_encodage"
    fi


	echo -e "${nb}\t${line}\t${code_http}\t${encodage}\t${nb_mot}" >> tableaux/tableau.tsv

done < "$ficher_URLS";
```
 ‚ùì‚ùì‚ùìJ'ai ensuite d√©couvert un probl√®me¬†: 
 
 Il y a un ph√©nom√®ne tr√®s √©trange dans ce code. Si j'ex√©cute metadonnee=$(curl -I -s -L "$line"), le r√©sultat de nb_mot=$(curl -s -L "$line" | wc -w) est erron√©, et vice-versa.
 
C'est-√†-dire je ne pouvais pas utiliser curl plusieurs fois, sinon les r√©sultats renvoy√©s ne correspondaient pas aux r√©sultats r√©els. J'ai demand√© √† chatGPT, et on m'a expliqu√© que c'√©tait d√ª au fait que j'ex√©cutais curl plusieurs fois sur la m√™me URL et que la r√©ponse du site web n'√©tait pas corrig√©e, ce qui entra√Ænait des r√©sultats incorrects. (Ce n'est peut-√™tre pas le probl√®me, car la premi√®re fois que j'ai utilis√© ce code, il a renvoy√© les bons r√©sultats, mais pour une raison inconnue, il a cess√© de fonctionner par la suite.)
 
ÊâÄ‰ª•ÊàëÁé∞Âú®ÁöÑ‰ªªÂä°ÊòØ, ÊâæÂà∞Âè™‰ΩøÁî®‰∏ÄÊ¨°curlÊù•ËææÂà∞ÊàëÂèØ‰ª•ÊèêÂèñ‰∏âÁßç‰ø°ÊÅØ(code, encodage, nombre de mot)ÁöÑÊñπÊ≥ï, Êàë‰πãÂâç‰∏∫‰∫ÜËøîÂõûÁöÑÊï∞ÊçÆ‰∏çË¶ÅÂ§™ËøáÂ∫ûÂ§ß, ‰ΩøÁî®ÁöÑÊòØcurl -I, ËøôÂè™‰ºöËøîÂõûËøô‰∏™ÁΩëÈ°µÁöÑmetadonne, ÊàëÁé∞Âú®Â∞ùËØï‰ΩøÁî®curl -i, Êù•ÂêåÊó∂ËøîÂõûËøô‰∏™ÁΩëÈ°µÁöÑheadÂíåbody, ËøôÊ†∑ÊàëÂ∞±ÂèØ‰ª•Âè™‰ΩøÁî®‰∏ÄÊ¨°curl, ÁÑ∂Âêé‰ªé‰∏≠ÊèêÂèñÊàëÊÉ≥Ë¶ÅÁöÑ‰ø°ÊÅØ  
‰ª•‰∏ãÊòØ‰øÆÊîπÂêéÁöÑcode, ËøôÊ†∑ËøêË°åÂá∫Êù•ÁöÑ‰ª£Á†ÅÊòØÊ≠£Á°ÆÁöÑ:
```bash
ficher_URLS=$1

if [ $# -ne 1 ]
then
    echo "ce programme demande un argument"
    exit
fi

if [ ! -f "$ficher_URLS" ]
then
    echo "vous devez indiquer un ficher"
    exit
fi

echo -e "nb\tline\tcode_http\tencodage\tnb_mot" > tableaux/tableau_fr.tsv

nb=0
meta=""
code_http=""
encodage=""
nb_mot=""
while read -r line;
do
    nb=$(expr $nb + 1)
    reponse=$(curl -s -i "$line")
    code_http=$(echo "$reponse" | head -n 1 | cut -d ' ' -f2) # la deuxi√®me colonne de la premi√®re ligne
    encodage=$(echo "$reponse" | grep content-type | sed -nE 's/.*charset=([^; ]*).*/\1/p' | tr -d '\r')
	# J'ai observ√© le contenu renvoy√© par curl -i -s, qui contenait plusieurs jeux de caract√®res, j'ai donc recherch√© directement content-type.
	# sed -nE 's/.*charset=([^; ]*).*/\1/p' : Utilisez l'expression r√©guli√®re sed pour extraire le nom d'encodage apr√®s charset=
	# Supprimez les √©ventuels caract√®res de retour chariot \r pour garantir une sortie propre
    nb_mot=$(echo "$reponse" | sed '1,/^\r$/d' | wc -w)

	# v√©rifier si on peut trouver la page
    if [ "$code_http" != "200" ]
    then
        code_http="Page_Not_Found"
    fi

	# v√©rifier on a bien l'encodage pour cette page
    if [ ! "$encodage" ]
    then
        encodage="No_encodage"
    fi


	echo -e "${nb}\t${line}\t${code_http}\t${encodage}\t${nb_mot}" >> tableaux/tableau_fr.tsv

done < "$ficher_URLS";
```
